{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You made a kernel!\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "import semantic_kernel.connectors.ai.open_ai as skaoai\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') #needed to get util in the path\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "deployment=\"gpt-4o\"\n",
    "service_id = \"default\"\n",
    "kernel.add_service(\n",
    "    skaoai.AzureChatCompletion(\n",
    "        deployment_name=deployment,\n",
    "        endpoint=endpoint,api_key=api_key)\n",
    "    )\n",
    "\n",
    "print(\"You made a kernel!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the functions in the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugins_directory = \"../sk_plugins\"\n",
    "lights_plugin = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"lights_plugin\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Autoinvoke, so semantic kernel decides when to call a plugin by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "from semantic_kernel.connectors.ai.function_call_behavior import FunctionCallBehavior\n",
    "\n",
    "# Consider the following car status {{car_plugins.GetCarStatus}}\n",
    "\n",
    "prompt = \"\"\"\n",
    "Perform the following actions:\n",
    "{{$input}}\n",
    "\"\"\"\n",
    "\n",
    "execution_settings = kernel.get_service(service_id).instantiate_prompt_execution_settings(\n",
    "    service_id=service_id, \n",
    "    temperature=0,  # Temperature can affect the execution of plugins!\n",
    "    max_tokens=2000,\n",
    "    function_call_behavior=FunctionCallBehavior.AutoInvokeKernelFunctions(),\n",
    "    )\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"summarize\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The actions to be performed\", is_required=True),\n",
    "    ],        \n",
    "    execution_settings=execution_settings,\n",
    ")\n",
    "\n",
    "light_function = kernel.add_function(\n",
    "    function_name=\"light_function\",\n",
    "    plugin_name=\"lights_plugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lights in the KITCHEN are currently OFF.\n"
     ]
    }
   ],
   "source": [
    "summary = await kernel.invoke(light_function, input=\"What is the status of the lights in the KITCHEN?\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing light status for KITCHEN to on\n",
      "Changing light status for KITCHEN to ON\n",
      "The lights in the KITCHEN have been switched on.\n"
     ]
    }
   ],
   "source": [
    "summary = await kernel.invoke(light_function, input=\"Switch on the the lights in the KITCHEN\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing light status for KITCHEN to 50%\n",
      "It seems that setting the light to 50% is not a valid option. The available statuses might be \"on\" or \"off\". Would you like to turn the light on or off in the kitchen?\n"
     ]
    }
   ],
   "source": [
    "summary = await kernel.invoke(light_function, input=\"Bring light to 50% to the KITCHEN\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lights in the KITCHEN are currently ON.\n"
     ]
    }
   ],
   "source": [
    "summary = await kernel.invoke(light_function, input=\"What is the status of the lights in the KITCHEN?\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lights in the BEDROOM are currently OFF.\n"
     ]
    }
   ],
   "source": [
    "summary = await kernel.invoke(light_function, input=\"What is the status of the lights in the BEDROOM?\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available rooms are:\n",
      "\n",
      "1. Living Room\n",
      "2. Kitchen\n",
      "3. Bedroom\n",
      "4. Bathroom\n",
      "5. Garage\n",
      "\n",
      "Would you like to perform any actions related to these rooms?\n"
     ]
    }
   ],
   "source": [
    "summary = await kernel.invoke(light_function, input=\"Which rooms are available?\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The possible statuses for the lights are typically \"on\" and \"off\".\n"
     ]
    }
   ],
   "source": [
    "summary = await kernel.invoke(light_function, input=\"What are the possible status for the lights\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
